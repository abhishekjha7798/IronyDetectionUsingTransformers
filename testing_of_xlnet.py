# -*- coding: utf-8 -*-
"""Testing of XLNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ih4vxtoc6Q1JYfMZrMgK__hutEQ-hc7K
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install transformers

import pandas as pd
import numpy as np
import tensorflow as tf
import torch
from transformers import *

tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)
#yahaan tak

#ye
import torch
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split


#from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification
#from pytorch_transformers import AdamW

from tqdm import tqdm, trange
import pandas as pd
import io
import numpy as np
import matplotlib.pyplot as plt
#% matplotlib inline

print(torch.__version__)

#start#
#
#
#
pytorch_model = XLNetForSequenceClassification.from_pretrained('/content/drive/My Drive/Colab Notebooks/testing of XLNets/',num_labels=4)
#pytorch_model = XLNetForSequenceClassification.from_pretrained('/content/drive/My Drive/Colab Notebooks/Models/abhishek',num_labels=4)

# Load dataset, tokenizer, model from pretrained model/vocabulary
tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')

from flask import Flask, render_template, request
from keras.preprocessing.sequence import pad_sequences
import pandas as pd
import numpy as np
import tensorflow as tf
#import torch
from transformers import *

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
n_gpu = torch.cuda.device_count()
torch.cuda.get_device_name(0)

# Importing pandas as pd 
import pandas as pd 
  
# Creating the first Dataframe using dictionary 
d3 = pd.DataFrame({"label":[0], 
                         "sentence":['Paris is the capital of france'],
                         "idx":[0]})

# Create sentence and label lists
sentences = d3.sentence.values

# We need to add special tokens at the beginning and end of each sentence for XLNet to work properly
sentences = [sentence + " [SEP] [CLS]" for sentence in sentences]
labels = d3.label.values

tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]


MAX_LEN = 128
# Use the XLNet tokenizer to convert the tokens to their index numbers in the XLNet vocabulary
input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]
# Pad our input tokens
input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype="long", truncating="post", padding="post")
# Create attention masks
attention_masks = []

# Create a mask of 1s for each token followed by 0s for padding
for seq in input_ids:
  seq_mask = [float(i>0) for i in seq]
  attention_masks.append(seq_mask) 

prediction_inputs = torch.tensor(input_ids)
prediction_masks = torch.tensor(attention_masks)
prediction_labels = torch.tensor(labels)
  
batch_size = 32  


prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)
prediction_sampler = SequentialSampler(prediction_data)
prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)

# Prediction on test set
pytorch_model.cuda()
# Put model in evaluation mode
pytorch_model.eval()

# Tracking variables 
predictions , true_labels = [], []

# Predict 
for batch in prediction_dataloader:
  # Add batch to GPU
  batch = tuple(t.to(device) for t in batch)
  # Unpack the inputs from our dataloader
  b_input_ids, b_input_mask, b_labels = batch
  # Telling the model not to compute or store gradients, saving memory and speeding up prediction
  with torch.no_grad():
    # Forward pass, calculate logit predictions
    outputs = pytorch_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)
    logits = outputs[0]

  # Move logits and labels to CPU
  logits = logits.detach().cpu().numpy()
  label_ids = b_labels.to('cpu').numpy()
  
  # Store predictions and true labels
  predictions.append(logits)
  true_labels.append(label_ids)

true_labels

predictions

######end#######